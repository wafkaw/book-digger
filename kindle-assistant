#!/usr/bin/env python3
"""
Kindle Reading Assistant - Unified CLI Management Tool
A comprehensive command-line interface for managing both CLI and Web services.
"""

import os
import sys
import argparse
import subprocess
import json
import time
import signal
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.absolute()
CLI_ROOT = PROJECT_ROOT / "cli"
WEB_ROOT = PROJECT_ROOT / "web"
SHARED_ROOT = PROJECT_ROOT / "shared"

# æ·»åŠ CLIæºç è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(CLI_ROOT))

class Colors:
    """ç»ˆç«¯é¢œè‰²ä»£ç """
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

class KindleAssistantCLI:
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.cli_root = CLI_ROOT
        self.web_root = WEB_ROOT
        self.shared_root = SHARED_ROOT
        
        # ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        dirs_to_create = [
            self.shared_root / "inputs",
            self.shared_root / "outputs", 
            self.shared_root / "data" / "cache",
            self.shared_root / "data" / "logs",
            self.web_root / "backend" / "uploads"
        ]
        
        for dir_path in dirs_to_create:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def _print_header(self, title):
        """æ‰“å°æ ‡é¢˜"""
        print(f"\n{Colors.HEADER}{Colors.BOLD}ğŸš€ {title}{Colors.ENDC}")
        print(f"{Colors.HEADER}{'='*50}{Colors.ENDC}\n")
    
    def _print_success(self, message):
        """æ‰“å°æˆåŠŸä¿¡æ¯"""
        print(f"{Colors.GREEN}âœ… {message}{Colors.ENDC}")
    
    def _print_warning(self, message):
        """æ‰“å°è­¦å‘Šä¿¡æ¯"""
        print(f"{Colors.WARNING}âš ï¸  {message}{Colors.ENDC}")
    
    def _print_error(self, message):
        """æ‰“å°é”™è¯¯ä¿¡æ¯"""
        print(f"{Colors.FAIL}âŒ {message}{Colors.ENDC}")
    
    def _print_info(self, message):
        """æ‰“å°ä¿¡æ¯"""
        print(f"{Colors.CYAN}â„¹ï¸  {message}{Colors.ENDC}")
    
    def _run_command(self, command, cwd=None, capture_output=False):
        """è¿è¡Œå‘½ä»¤"""
        try:
            if cwd:
                os.chdir(cwd)
            
            if capture_output:
                result = subprocess.run(command, shell=True, capture_output=True, text=True)
                return result.returncode == 0, result.stdout, result.stderr
            else:
                result = subprocess.run(command, shell=True)
                return result.returncode == 0, "", ""
        except Exception as e:
            return False, "", str(e)
    
    def _is_web_running(self):
        """æ£€æŸ¥WebæœåŠ¡æ˜¯å¦è¿è¡Œ"""
        try:
            result = subprocess.run(
                "docker-compose ps -q", 
                shell=True, 
                cwd=self.web_root,
                capture_output=True, 
                text=True
            )
            return len(result.stdout.strip()) > 0
        except:
            return False
    
    def _get_web_status(self):
        """è·å–WebæœåŠ¡çŠ¶æ€"""
        try:
            result = subprocess.run(
                "docker-compose ps", 
                shell=True, 
                cwd=self.web_root,
                capture_output=True, 
                text=True
            )
            return result.stdout
        except:
            return "âŒ Unable to get status"

    # ============ æœåŠ¡ç®¡ç†å‘½ä»¤ ============
    
    def start_web(self):
        """å¯åŠ¨WebæœåŠ¡"""
        self._print_header("Starting Web Services")
        
        if self._is_web_running():
            self._print_warning("Web services are already running")
            return
        
        self._print_info("Starting Docker Compose services...")
        success, stdout, stderr = self._run_command(
            "docker-compose up -d", 
            cwd=self.web_root
        )
        
        if success:
            self._print_success("Web services started successfully!")
            self._print_info("Frontend: http://localhost:3000")
            self._print_info("Backend API: http://localhost:8000")
            self._print_info("API Docs: http://localhost:8000/docs")
            self._print_info("Celery Monitor: http://localhost:5555")
        else:
            self._print_error("Failed to start web services")
            if stderr:
                print(stderr)
    
    def stop_web(self):
        """åœæ­¢WebæœåŠ¡"""
        self._print_header("Stopping Web Services")
        
        if not self._is_web_running():
            self._print_warning("Web services are not running")
            return
        
        self._print_info("Stopping Docker Compose services...")
        success, stdout, stderr = self._run_command(
            "docker-compose down", 
            cwd=self.web_root
        )
        
        if success:
            self._print_success("Web services stopped successfully!")
        else:
            self._print_error("Failed to stop web services")
            if stderr:
                print(stderr)
    
    def restart_web(self):
        """é‡å¯WebæœåŠ¡"""
        self._print_header("Restarting Web Services")
        self.stop_web()
        time.sleep(2)
        self.start_web()
    
    def status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
        self._print_header("System Status")
        
        # WebæœåŠ¡çŠ¶æ€
        print(f"{Colors.BOLD}ğŸŒ Web Services:{Colors.ENDC}")
        if self._is_web_running():
            self._print_success("Running")
            print(self._get_web_status())
        else:
            self._print_warning("Stopped")
        
        # ç›®å½•çŠ¶æ€
        print(f"\n{Colors.BOLD}ğŸ“ Directories:{Colors.ENDC}")
        dirs_to_check = {
            "CLI Source": self.cli_root / "src",
            "Web Backend": self.web_root / "backend",
            "Web Frontend": self.web_root / "frontend",
            "Shared Inputs": self.shared_root / "inputs",
            "Shared Outputs": self.shared_root / "outputs",
            "Cache": self.shared_root / "data" / "cache"
        }
        
        for name, path in dirs_to_check.items():
            if path.exists():
                self._print_success(f"{name}: {path}")
            else:
                self._print_error(f"{name}: {path} (Missing)")
        
        # è¾“å…¥æ–‡ä»¶
        input_files = list((self.shared_root / "inputs").glob("*.html"))
        print(f"\n{Colors.BOLD}ğŸ“„ Input Files:{Colors.ENDC}")
        if input_files:
            for file in input_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"  â€¢ {file.name}")
            if len(input_files) > 5:
                print(f"  ... and {len(input_files) - 5} more")
        else:
            self._print_warning("No Kindle HTML files found in shared/inputs/")

    # ============ åˆ†æå¤„ç†å‘½ä»¤ ============
    
    def analyze(self, file_path=None, debug=False, output_format='obsidian', output_path=None,
                llm_key=None, llm_base_url=None, llm_model=None):
        """è¿è¡Œåˆ†æå¤„ç†"""
        self._print_header("Running Analysis")
        
        # æ£€æŸ¥CLIç¯å¢ƒ
        if not (self.cli_root / "requirements.txt").exists():
            self._print_error("CLI environment not found. Run 'init' first.")
            return
        
        try:
            # åŠ è½½é…ç½®
            sys.path.insert(0, str(self.cli_root))
            from src.config.config_manager import config_manager
            
            config = config_manager.load_config()
            
            # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            config = config_manager.apply_cli_args(
                config,
                llm_key=llm_key,
                llm_base_url=llm_base_url,
                llm_model=llm_model,
                debug=debug,
                format=output_format,
                output=output_path
            )
            
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            self._print_info(f"LLM Provider: {config.llm.provider} ({config.llm.model})")
            if config.llm.api_key:
                self._print_info(f"API Key: {config.llm.api_key[:8]}...")
            else:
                self._print_warning("No API key configured!")
                
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['OPENAI_API_KEY'] = config.llm.api_key
            env['OPENAI_BASE_URL'] = config.llm.base_url
            env['OPENAI_MODEL'] = config.llm.model
            env['AI_BATCH_SIZE'] = str(config.processing.batch_size)
            env['ENABLE_CACHING'] = str(config.processing.enable_caching).lower()
            env['DEBUG_MODE'] = str(config.processing.debug_mode).lower()
            
            # å¤„ç†è¾“å…¥æ–‡ä»¶è·¯å¾„
            if file_path:
                # æ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
                if not os.path.isabs(file_path):
                    # é¦–å…ˆå°è¯•ç›¸å¯¹äºå½“å‰ç›®å½•
                    if os.path.exists(file_path):
                        file_path = os.path.abspath(file_path)
                    else:
                        # ç„¶åå°è¯•ç›¸å¯¹äºshared/inputsç›®å½•
                        inputs_path = self.shared_root / "inputs" / file_path
                        if inputs_path.exists():
                            file_path = str(inputs_path)
                        else:
                            # æœ€åå°è¯•ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                            file_path = str(self.project_root / file_path)
                
                if not os.path.exists(file_path):
                    self._print_error(f"File not found: {file_path}")
                    return
                
                self._print_info(f"Processing file: {file_path}")
            
            # å¤„ç†è¾“å‡ºæ ¼å¼å’Œè·¯å¾„
            if not output_format:
                output_format = config.output.default_format
            if not output_path:
                output_path = config.output.output_dir if config.output.output_dir else None
                
            self._print_info(f"Output format: {output_format}")
            if output_path:
                self._print_info(f"Output path: {output_path}")
            
            # å‡†å¤‡å‘½ä»¤
            cmd_parts = ["python", "main.py"]
            if config.processing.debug_mode:
                cmd_parts.append("--debug")
            if file_path:
                cmd_parts.extend(["--file", file_path])
            if output_format:
                cmd_parts.extend(["--format", output_format])
            if output_path:
                cmd_parts.extend(["--output", output_path])
            
            self._print_info(f"Running: {' '.join(cmd_parts)}")
            self._print_info("This may take 5-10 minutes for processing...")
            
            # è¿è¡Œåˆ†æ
            success, stdout, stderr = self._run_command_with_args(cmd_parts, cwd=self.cli_root, env=env)
            
            if success:
                self._print_success("Analysis completed successfully!")
                
                if output_format == 'json':
                    self._handle_json_output(output_path)
                else:
                    self._print_info("Check shared/outputs/ for generated Obsidian vault")
                    if output_path:
                        self._copy_output_to_destination(output_path)
            else:
                self._print_error("Analysis failed")
                if stderr:
                    print(f"Error: {stderr}")
                    
        except ImportError as e:
            self._print_error(f"Failed to import configuration manager: {str(e)}")
            # é™çº§åˆ°åŸæœ‰é€»è¾‘
            self._print_warning("Falling back to basic configuration...")
            self._run_basic_analysis(file_path, debug, output_format, output_path, 
                                    llm_key, llm_base_url, llm_model)
        except Exception as e:
            self._print_error(f"Analysis failed with exception: {str(e)}")
    
    def _run_basic_analysis(self, file_path=None, debug=False, output_format='obsidian', 
                           output_path=None, llm_key=None, llm_base_url=None, llm_model=None):
        """åŸºç¡€åˆ†ææµç¨‹ï¼ˆé™çº§æ¨¡å¼ï¼‰"""
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¸´æ—¶LLMé…ç½®ï¼‰
        env = os.environ.copy()
        if llm_key:
            env['OPENAI_API_KEY'] = llm_key
        if llm_base_url:
            env['OPENAI_BASE_URL'] = llm_base_url
        if llm_model:
            env['OPENAI_MODEL'] = llm_model
        
        # å‡†å¤‡å‘½ä»¤
        cmd_parts = ["python", "main.py"]
        if debug:
            cmd_parts.append("--debug")
        if file_path:
            cmd_parts.extend(["--file", file_path])
        
        cmd = " ".join(cmd_parts)
        
        try:
            # ä½¿ç”¨è‡ªå®šä¹‰ç¯å¢ƒå˜é‡è¿è¡Œ
            success, stdout, stderr = self._run_command_with_env(cmd, cwd=self.cli_root, env=env)
            
            if success:
                self._print_success("Analysis completed successfully!")
                
                if output_format == 'json':
                    self._handle_json_output(output_path)
                else:
                    self._print_info("Check shared/outputs/ for generated Obsidian vault")
                    if output_path:
                        self._copy_output_to_destination(output_path)
            else:
                self._print_error("Analysis failed")
                if stderr:
                    print(f"Error: {stderr}")
        except Exception as e:
            self._print_error(f"Basic analysis failed: {str(e)}")
    
    def _run_command_with_args(self, command_args, cwd=None, env=None):
        """è¿è¡Œå¸¦ç¯å¢ƒå˜é‡çš„å‘½ä»¤ï¼ˆå‚æ•°åˆ—è¡¨å½¢å¼ï¼Œæ›´å®‰å…¨ï¼‰"""
        try:
            result = subprocess.run(
                command_args, 
                shell=False,  # ä½¿ç”¨å‚æ•°åˆ—è¡¨ï¼Œä¸éœ€è¦shell
                env=env,
                cwd=cwd,
                capture_output=True, 
                text=True
            )
            
            return result.returncode == 0, result.stdout, result.stderr
        except Exception as e:
            return False, "", str(e)
    
    def _run_command_with_env(self, command, cwd=None, env=None):
        """è¿è¡Œå¸¦ç¯å¢ƒå˜é‡çš„å‘½ä»¤ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼Œä»…ç”¨äºå…¼å®¹æ€§ï¼‰"""
        try:
            if cwd:
                original_cwd = os.getcwd()
                os.chdir(cwd)
            
            result = subprocess.run(
                command, 
                shell=True, 
                env=env,
                capture_output=True, 
                text=True
            )
            
            if cwd:
                os.chdir(original_cwd)
                
            return result.returncode == 0, result.stdout, result.stderr
        except Exception as e:
            return False, "", str(e)
    
    def _handle_json_output(self, output_path=None):
        """å¤„ç†JSONæ ¼å¼è¾“å‡º"""
        self._print_info("Converting to JSON format...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„Obsidianè¾“å‡º
        output_dir = self.shared_root / "outputs"
        if not output_dir.exists() or not any(output_dir.iterdir()):
            self._print_error("No output generated to convert")
            return
        
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„Obsidian vault
            obsidian_vaults = [d for d in output_dir.iterdir() if d.is_dir()]
            if not obsidian_vaults:
                self._print_error("No Obsidian vault found in outputs")
                return
            
            # ä½¿ç”¨æœ€æ–°çš„vaultï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
            latest_vault = max(obsidian_vaults, key=lambda x: x.stat().st_mtime)
            
            # å¯¼å…¥JSONç”Ÿæˆå™¨
            sys.path.insert(0, str(self.cli_root))
            from src.output.json_generator import create_json_from_obsidian
            
            # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if output_path:
                json_file = Path(output_path)
                if json_file.suffix != '.json':
                    json_file = json_file.with_suffix('.json')
            else:
                # ä½¿ç”¨vaultåç§°ä½œä¸ºJSONæ–‡ä»¶å
                json_file = output_dir / f"{latest_vault.name}.json"
            
            # ç”ŸæˆJSON
            json_data = create_json_from_obsidian(str(latest_vault), str(json_file))
            
            self._print_success(f"JSON output generated: {json_file}")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = json_data.get('statistics', {})
            self._print_info(f"Converted {stats.get('total_nodes', 0)} nodes and {stats.get('total_relationships', 0)} relationships")
            
        except ImportError as e:
            self._print_error(f"Failed to import JSON generator: {str(e)}")
        except Exception as e:
            self._print_error(f"Failed to create JSON output: {str(e)}")
    
    def _copy_output_to_destination(self, output_path):
        """å¤åˆ¶è¾“å‡ºåˆ°æŒ‡å®šç›®å½•"""
        try:
            import shutil
            source_dir = self.shared_root / "outputs"
            dest_path = Path(output_path)
            
            if dest_path.suffix:
                # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶åï¼Œå¤åˆ¶åˆ°çˆ¶ç›®å½•
                dest_dir = dest_path.parent
                dest_dir.mkdir(parents=True, exist_ok=True)
            else:
                # å¦‚æœæ˜¯ç›®å½•ï¼Œç›´æ¥å¤åˆ¶
                dest_dir = dest_path
                dest_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ•´ä¸ªè¾“å‡ºç›®å½•
            if source_dir.exists():
                for item in source_dir.iterdir():
                    if item.is_dir():
                        shutil.copytree(item, dest_dir / item.name, dirs_exist_ok=True)
                    else:
                        shutil.copy2(item, dest_dir)
                
                self._print_success(f"Output copied to: {dest_dir}")
        except Exception as e:
            self._print_error(f"Failed to copy output: {str(e)}")
    
    def process_web(self, file_path):
        """é€šè¿‡Web APIå¤„ç†æ–‡ä»¶"""
        self._print_header("Processing via Web API")
        
        if not self._is_web_running():
            self._print_error("Web services not running. Start them first: kindle-assistant start")
            return
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ APIè°ƒç”¨é€»è¾‘
        self._print_info("Web API processing not yet implemented")
        self._print_info("Use the web interface at http://localhost:3000")

    # ============ é…ç½®å’Œç»´æŠ¤å‘½ä»¤ ============
    
    def init(self):
        """åˆå§‹åŒ–é¡¹ç›®ç¯å¢ƒ"""
        self._print_header("Initializing Project Environment")
        
        # æ£€æŸ¥Pythonç¯å¢ƒ
        self._print_info("Checking Python environment...")
        success, stdout, stderr = self._run_command("python --version", capture_output=True)
        if success:
            self._print_success(f"Python: {stdout.strip()}")
        else:
            self._print_error("Python not found")
            return
        
        # å®‰è£…CLIä¾èµ–
        if (self.cli_root / "requirements.txt").exists():
            self._print_info("Installing CLI dependencies...")
            success, stdout, stderr = self._run_command(
                "pip install -r requirements.txt", 
                cwd=self.cli_root
            )
            if success:
                self._print_success("CLI dependencies installed")
            else:
                self._print_error("Failed to install CLI dependencies")
                print(stderr)
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_file = self.cli_root / ".env"
        if not env_file.exists():
            self._print_warning("Environment file not found")
            self._print_info("Copy .env.example to .env and configure your API keys")
        else:
            self._print_success("Environment file exists")
        
        # æ£€æŸ¥Docker
        self._print_info("Checking Docker...")
        success, stdout, stderr = self._run_command("docker --version", capture_output=True)
        if success:
            self._print_success(f"Docker: {stdout.strip()}")
        else:
            self._print_warning("Docker not found (needed for Web services)")
        
        self._print_success("Initialization complete!")
    
    def config(self, action=None, key=None, value=None, api_key=None, model=None):
        """é…ç½®ç®¡ç†"""
        self._print_header("Configuration Management")
        
        try:
            # å¯¼å…¥é…ç½®ç®¡ç†å™¨
            sys.path.insert(0, str(self.cli_root))
            from src.config.config_manager import config_manager
            
            if action == "list":
                config = config_manager.load_config()
                self._display_config(config)
            
            elif action == "list-providers":
                providers = config_manager.get_llm_providers()
                self._display_providers(providers)
            
            elif action == "set-llm" and key:
                if not api_key:
                    self._print_error("API key required for set-llm. Use --api-key parameter")
                    return
                
                success = config_manager.set_provider(key, api_key)
                if success:
                    if model:
                        # æ›´æ–°æ¨¡å‹
                        config = config_manager.load_config()
                        config.llm.model = model
                        config_manager.save_config(config)
                    
                    self._print_success(f"LLM provider '{key}' configured successfully")
                    self._print_info("Use 'config test-llm' to verify the connection")
                else:
                    self._print_error(f"Unknown provider: {key}")
                    self._print_info("Use 'config list-providers' to see available providers")
            
            elif action == "test-llm":
                config = config_manager.load_config()
                if config_manager.test_llm_connection(config):
                    self._print_success("LLM configuration is valid")
                    self._print_info(f"Provider: {config.llm.provider}")
                    self._print_info(f"Model: {config.llm.model}")
                else:
                    self._print_error("LLM configuration test failed")
                    self._print_info("Check your API key and provider settings")
            
            elif action == "set" and key and value:
                self._print_info(f"Setting {key} = {value}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šé…ç½®é¡¹çš„è®¾ç½®é€»è¾‘
                self._print_warning("Generic config setting not yet implemented")
            
            else:
                self._print_info("Available actions:")
                self._print_info("  config list                    # Show current configuration")
                self._print_info("  config list-providers          # Show available LLM providers")
                self._print_info("  config set-llm PROVIDER --api-key KEY [--model MODEL]")
                self._print_info("  config test-llm               # Test LLM connection")
        
        except ImportError as e:
            self._print_error(f"Failed to import configuration manager: {str(e)}")
        except Exception as e:
            self._print_error(f"Configuration error: {str(e)}")
    
    def _display_config(self, config):
        """æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
        print(f"{Colors.BOLD}ğŸ”§ Current Configuration:{Colors.ENDC}\n")
        
        # LLMé…ç½®
        print(f"{Colors.BLUE}LLM Configuration:{Colors.ENDC}")
        print(f"  Provider: {config.llm.provider}")
        print(f"  Model: {config.llm.model}")
        print(f"  Base URL: {config.llm.base_url}")
        api_key_display = f"{config.llm.api_key[:8]}..." if config.llm.api_key else "Not set"
        print(f"  API Key: {api_key_display}")
        
        # å¤„ç†é…ç½®
        print(f"\n{Colors.BLUE}Processing Configuration:{Colors.ENDC}")
        print(f"  Batch Size: {config.processing.batch_size}")
        print(f"  Enable Caching: {config.processing.enable_caching}")
        print(f"  Importance Threshold: {config.processing.importance_threshold}")
        print(f"  Max Concept Length: {config.processing.max_concept_length}")
        print(f"  Debug Mode: {config.processing.debug_mode}")
        
        # è¾“å‡ºé…ç½®
        print(f"\n{Colors.BLUE}Output Configuration:{Colors.ENDC}")
        print(f"  Default Format: {config.output.default_format}")
        print(f"  Output Directory: {config.output.output_dir or 'Default (shared/outputs)'}")
        print(f"  JSON Pretty Print: {config.output.json_pretty}")
        print(f"  Obsidian Template: {config.output.obsidian_template}")
    
    def _display_providers(self, providers):
        """æ˜¾ç¤ºLLMæä¾›å•†ä¿¡æ¯"""
        print(f"{Colors.BOLD}ğŸ“¡ Available LLM Providers:{Colors.ENDC}\n")
        
        for name, info in providers.items():
            print(f"{Colors.GREEN}â€¢ {name.upper()}{Colors.ENDC}")
            print(f"  Description: {info['description']}")
            print(f"  Base URL: {info['base_url']}")
            print(f"  Default Model: {info['model']}")
            print()
    
    def clean(self, target="all"):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        self._print_header("Cleaning Temporary Files")
        
        clean_targets = {
            "cache": self.shared_root / "data" / "cache",
            "logs": self.shared_root / "data" / "logs", 
            "uploads": self.web_root / "backend" / "uploads",
            "outputs": self.shared_root / "outputs"
        }
        
        if target == "all":
            targets = clean_targets.values()
        elif target in clean_targets:
            targets = [clean_targets[target]]
        else:
            self._print_error(f"Unknown target: {target}")
            self._print_info(f"Available targets: {', '.join(clean_targets.keys())}, all")
            return
        
        for target_path in targets:
            if target_path.exists():
                self._print_info(f"Cleaning {target_path}...")
                success, _, _ = self._run_command(f"rm -rf {target_path}/*")
                if success:
                    self._print_success(f"Cleaned {target_path}")
                else:
                    self._print_error(f"Failed to clean {target_path}")
        
        # é‡æ–°åˆ›å»ºå¿…è¦ç›®å½•
        self._ensure_directories()
    
    def logs(self, service="all", lines=50):
        """æŸ¥çœ‹æ—¥å¿—"""
        self._print_header("Service Logs")
        
        if service in ["all", "web"] and self._is_web_running():
            self._print_info("Web Service Logs:")
            self._run_command(f"docker-compose logs --tail={lines}", cwd=self.web_root)
        
        # CLIæ—¥å¿—
        log_dir = self.shared_root / "data" / "logs"
        if log_dir.exists() and service in ["all", "cli"]:
            self._print_info("CLI Logs:")
            log_files = list(log_dir.glob("*.log"))
            for log_file in log_files[-3:]:  # æœ€è¿‘3ä¸ªæ—¥å¿—æ–‡ä»¶
                print(f"\n--- {log_file.name} ---")
                self._run_command(f"tail -n {lines} {log_file}")
    
    def health(self):
        """å¥åº·æ£€æŸ¥"""
        self._print_header("Health Check")
        
        # æ£€æŸ¥WebæœåŠ¡å¥åº·
        if self._is_web_running():
            self._print_info("Checking Web API health...")
            try:
                import requests
                response = requests.get("http://localhost:8000/health", timeout=5)
                if response.status_code == 200:
                    self._print_success("Web API: Healthy")
                else:
                    self._print_warning(f"Web API: Status {response.status_code}")
            except:
                self._print_error("Web API: Unreachable")
        else:
            self._print_warning("Web services not running")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        self._print_info("Checking disk usage...")
        success, stdout, stderr = self._run_command("df -h .", capture_output=True)
        if success:
            lines = stdout.strip().split('\n')
            if len(lines) >= 2:
                print(f"Disk usage: {lines[1].split()[4]} used")
    
    def version(self):
        """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        self._print_header("Version Information")
        
        print(f"{Colors.BOLD}Kindle Reading Assistant CLI{Colors.ENDC}")
        print(f"Version: 2.0.0")
        print(f"Project: {self.project_root}")
        print(f"CLI: {self.cli_root}")
        print(f"Web: {self.web_root}")
        print(f"Shared: {self.shared_root}")

def main():
    parser = argparse.ArgumentParser(
        description="Kindle Reading Assistant - Unified CLI Management Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  kindle-assistant init                    # Initialize project environment
  kindle-assistant start                  # Start web services
  kindle-assistant analyze                # Run CLI analysis on all files
  kindle-assistant analyze --debug --file book.html  # Debug analysis on specific file
  kindle-assistant status                 # Show system status
  kindle-assistant logs web               # Show web service logs
  kindle-assistant clean cache            # Clean cache directory
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # æœåŠ¡ç®¡ç†å‘½ä»¤
    subparsers.add_parser('start', help='Start web services')
    subparsers.add_parser('stop', help='Stop web services')
    subparsers.add_parser('restart', help='Restart web services')
    subparsers.add_parser('status', help='Show system status')
    
    # åˆ†æå¤„ç†å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='Run CLI analysis')
    analyze_parser.add_argument('--file', help='Specific file to analyze')
    analyze_parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    analyze_parser.add_argument('--format', choices=['obsidian', 'json'], default='obsidian',
                               help='Output format: obsidian (default) or json')
    analyze_parser.add_argument('--output', '-o', help='Output file/directory path')
    
    # LLMé…ç½®å‚æ•°
    analyze_parser.add_argument('--llm-key', help='Custom LLM API key')
    analyze_parser.add_argument('--llm-base-url', help='Custom LLM base URL')
    analyze_parser.add_argument('--llm-model', help='Custom LLM model name')
    
    process_parser = subparsers.add_parser('process', help='Process via Web API')
    process_parser.add_argument('file', help='File to process')
    
    # é…ç½®å’Œç»´æŠ¤å‘½ä»¤
    subparsers.add_parser('init', help='Initialize project environment')
    
    config_parser = subparsers.add_parser('config', help='Configuration management')
    config_parser.add_argument('action', 
                               choices=['list', 'set', 'set-llm', 'list-providers', 'test-llm'], 
                               help='Config action')
    config_parser.add_argument('key', nargs='?', help='Config key or provider name')
    config_parser.add_argument('value', nargs='?', help='Config value')
    config_parser.add_argument('--api-key', help='API key for set-llm action')
    config_parser.add_argument('--model', help='Model name for set-llm action')
    
    clean_parser = subparsers.add_parser('clean', help='Clean temporary files')
    clean_parser.add_argument('target', nargs='?', default='all', 
                             choices=['all', 'cache', 'logs', 'uploads', 'outputs'],
                             help='What to clean')
    
    logs_parser = subparsers.add_parser('logs', help='View service logs')
    logs_parser.add_argument('service', nargs='?', default='all',
                            choices=['all', 'web', 'cli'], help='Which service logs')
    logs_parser.add_argument('--lines', type=int, default=50, help='Number of lines')
    
    subparsers.add_parser('health', help='Health check')
    subparsers.add_parser('version', help='Show version information')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    cli = KindleAssistantCLI()
    
    # è·¯ç”±å‘½ä»¤åˆ°ç›¸åº”æ–¹æ³•
    if args.command == 'start':
        cli.start_web()
    elif args.command == 'stop':
        cli.stop_web()
    elif args.command == 'restart':
        cli.restart_web()
    elif args.command == 'status':
        cli.status()
    elif args.command == 'analyze':
        cli.analyze(
            file_path=args.file, 
            debug=args.debug,
            output_format=args.format,
            output_path=args.output,
            llm_key=args.llm_key,
            llm_base_url=args.llm_base_url,
            llm_model=args.llm_model
        )
    elif args.command == 'process':
        cli.process_web(args.file)
    elif args.command == 'init':
        cli.init()
    elif args.command == 'config':
        cli.config(args.action, args.key, args.value, args.api_key, args.model)
    elif args.command == 'clean':
        cli.clean(args.target)
    elif args.command == 'logs':
        cli.logs(args.service, args.lines)
    elif args.command == 'health':
        cli.health()
    elif args.command == 'version':
        cli.version()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()