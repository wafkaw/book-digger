"""
Obsidian generator for creating markdown files from book analysis
"""
import os
import json
from typing import Dict, Any, List, Tuple
from pathlib import Path
from datetime import datetime
import logging

from ..config.models import Book, AIAnalysisResult, KnowledgeGraph


class ObsidianGenerator:
    """Generate Obsidian-compatible markdown files"""
    
    def __init__(self, output_dir: str = "obsidian_vault"):
        self.output_dir = Path(output_dir)
        self.logger = logging.getLogger(__name__)
        
        # Create output directory
        self.output_dir.mkdir(exist_ok=True)
        
        # Create subdirectories
        self.books_dir = self.output_dir / "books"
        self.concepts_dir = self.output_dir / "concepts"
        self.people_dir = self.output_dir / "people"
        self.themes_dir = self.output_dir / "themes"
        
        for directory in [self.books_dir, self.concepts_dir, self.people_dir, self.themes_dir]:
            directory.mkdir(exist_ok=True)
    
    def generate_book_files(self, book: Book, analysis_result: Dict[str, Any], aggregated_mode: bool = True):
        """Generate all files for a book with optional aggregation mode"""
        if aggregated_mode:
            # Generate aggregated book-level files (fewer, richer files)
            self._generate_aggregated_book_files(book, analysis_result)
        else:
            # Generate individual files for each concept/theme (original mode)
            self._generate_individual_files(book, analysis_result)
        
        # Always generate index file
        self._generate_index_file()
    
    def _generate_aggregated_book_files(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate aggregated book-level files"""
        # Generate main book file with comprehensive analysis
        self._generate_comprehensive_book_file(book, analysis_result)
        
        # Generate aggregated concept overview file
        self._generate_concepts_overview_file(book, analysis_result)
        
        # Generate aggregated themes overview file  
        self._generate_themes_overview_file(book, analysis_result)
        
        # Generate people file (if any people mentioned)
        all_people = set()
        for result in analysis_result["analysis_results"]:
            all_people.update(result.get("people", []))
        
        if all_people:
            self._generate_people_overview_file(book, analysis_result, list(all_people))
    
    def _generate_individual_files(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate individual files for each concept/theme (original mode)"""
        # Generate main book file
        self._generate_book_file(book, analysis_result)
        
        # Generate concept files
        self._generate_concept_files(book, analysis_result)
        
        # Generate people files
        self._generate_people_files(book, analysis_result)
        
        # Generate theme files
        self._generate_theme_files(book, analysis_result)
    
    def _generate_book_file(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate main book file"""
        filename = self._sanitize_filename(book.metadata.title) + ".md"
        filepath = self.books_dir / filename
        
        content = self._generate_book_content(book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated book file: {filepath}")
    
    def _generate_comprehensive_book_file(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate comprehensive book file with full analysis"""
        filename = self._sanitize_filename(book.metadata.title) + "_å…¨é¢åˆ†æž.md"
        filepath = self.books_dir / filename
        
        content = self._generate_comprehensive_book_content(book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated comprehensive book file: {filepath}")
    
    def _generate_comprehensive_book_content(self, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate comprehensive book content"""
        sections = []
        
        # Title and metadata
        sections.append(f"# {book.metadata.title} - å…¨é¢åˆ†æž")
        sections.append("")
        sections.append(f"**ä½œè€…**: {book.metadata.author}")
        sections.append(f"**åˆ†æžæ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}")
        sections.append(f"**æ ‡æ³¨æ•°é‡**: {len(book.highlights)}")
        sections.append("")
        
        # Book summary
        if "book_summary" in analysis_result:
            sections.append("## ðŸ“š ä¹¦ç±æ¦‚è¿°")
            sections.append("")
            sections.append(analysis_result["book_summary"])
            sections.append("")
        
        # Core concepts aggregation
        all_concepts = set()
        for result in analysis_result["analysis_results"]:
            all_concepts.update(result.get("concepts", []))
        
        if all_concepts:
            sections.append("## ðŸ’¡ æ ¸å¿ƒæ¦‚å¿µ")
            sections.append("")
            for concept in sorted(all_concepts):
                related_highlights = self._get_highlights_for_concept(concept, analysis_result)
                sections.append(f"### {concept}")
                sections.append("")
                if related_highlights:
                    sections.append("ç›¸å…³æ ‡æ³¨:")
                    for highlight in related_highlights[:3]:  # Show top 3
                        sections.append(f"- {highlight[:100]}...")
                sections.append("")
        
        # Core themes aggregation  
        all_themes = set()
        for result in analysis_result["analysis_results"]:
            all_themes.update(result.get("themes", []))
        
        if all_themes:
            sections.append("## ðŸŽ­ ä¸»è¦ä¸»é¢˜")
            sections.append("")
            for theme in sorted(all_themes):
                related_highlights = self._get_highlights_for_theme(theme, analysis_result)
                sections.append(f"### {theme}")
                sections.append("")
                if related_highlights:
                    sections.append("ç›¸å…³æ ‡æ³¨:")
                    for highlight in related_highlights[:3]:
                        sections.append(f"- {highlight[:100]}...")
                sections.append("")
        
        # Important highlights by score
        important_highlights = []
        for i, result in enumerate(analysis_result["analysis_results"]):
            if result.get("importance_score", 0) >= 0.7:
                important_highlights.append((book.highlights[i], result))
        
        if important_highlights:
            sections.append("## â­ é‡è¦æ ‡æ³¨")
            sections.append("")
            for highlight, result in sorted(important_highlights, key=lambda x: x[1].get("importance_score", 0), reverse=True):
                sections.append(f"### é‡è¦æ€§: {result.get('importance_score', 0):.1f}")
                sections.append("")
                sections.append(f"> {highlight.content}")
                sections.append("")
                if result.get("summary"):
                    sections.append(f"**åˆ†æž**: {result['summary']}")
                    sections.append("")
        
        return "\n".join(sections)
    
    def _get_highlights_for_concept(self, concept: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Get highlights related to a specific concept"""
        highlights = []
        for i, result in enumerate(analysis_result["analysis_results"]):
            if concept in result.get("concepts", []):
                highlights.append(analysis_result["book"]["highlights"][i]["content"])
        return highlights
    
    def _get_highlights_for_theme(self, theme: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Get highlights related to a specific theme"""
        highlights = []
        for i, result in enumerate(analysis_result["analysis_results"]):
            if theme in result.get("themes", []):
                highlights.append(analysis_result["book"]["highlights"][i]["content"])
        return highlights
    
    def _generate_book_content(self, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate content for book file"""
        metadata = book.metadata
        
        # Build content sections
        sections = []
        
        # Header
        sections.append(f"# {metadata.title}")
        sections.append("")
        sections.append(f"**ä½œè€…**: {metadata.author}")
        if metadata.subtitle:
            sections.append(f"**å‰¯æ ‡é¢˜**: {metadata.subtitle}")
        if metadata.translator:
            sections.append(f"**è¯‘è€…**: {metadata.translator}")
        if metadata.publisher:
            sections.append(f"**å‡ºç‰ˆç¤¾**: {metadata.publisher}")
        if metadata.year:
            sections.append(f"**å‡ºç‰ˆå¹´ä»½**: {metadata.year}")
        sections.append(f"**æ ‡æ³¨æ€»æ•°**: {len(book.highlights)}")
        sections.append(f"**å¤„ç†æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        sections.append("")
        
        # Summary
        if "book_summary" in analysis_result:
            sections.append("## ðŸ“Š åˆ†æžæ‘˜è¦")
            sections.append(analysis_result["book_summary"])
            sections.append("")
        
        # Statistics
        if "statistics" in analysis_result:
            stats = analysis_result["statistics"]
            sections.append("## ðŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
            sections.append(f"- **æ€»æ ‡æ³¨æ•°**: {stats.get('total_highlights', 0)}")
            sections.append(f"- **å¹³å‡é‡è¦æ€§**: {stats.get('average_importance', 0):.2f}")
            sections.append("")
            
            # Top concepts
            if "top_concepts" in stats and stats["top_concepts"]:
                sections.append("### ðŸ”¥ æ ¸å¿ƒæ¦‚å¿µ")
                for concept, count in stats["top_concepts"][:5]:
                    sections.append(f"- [[{concept}]] ({count}æ¬¡)")
                sections.append("")
            
            # Top themes
            if "top_themes" in stats and stats["top_themes"]:
                sections.append("### ðŸŽ¯ ä¸»è¦ä¸»é¢˜")
                for theme, count in stats["top_themes"][:3]:
                    sections.append(f"- [[{theme}]] ({count}æ¬¡)")
                sections.append("")
        
        # Highlights by section
        sections.append("## ðŸ“ æ ‡æ³¨å†…å®¹")
        highlights_by_section = book.get_highlights_by_section()
        
        for section, highlights in highlights_by_section.items():
            sections.append(f"### {section}")
            sections.append("")
            
            for highlight in highlights:
                # Find analysis result for this highlight
                highlight_analysis = self._find_highlight_analysis(highlight, analysis_result["analysis_results"])
                
                sections.append(f"#### æ ‡æ³¨ - ç¬¬{highlight.location.page}é¡µ (ä½ç½®{highlight.location.position})")
                sections.append("")
                sections.append(f"> {highlight.content}")
                sections.append("")
                
                if highlight_analysis:
                    # Add analysis information
                    if highlight_analysis.get("concepts"):
                        concepts = [f"[[{c}]]" for c in highlight_analysis["concepts"]]
                        sections.append(f"**æ¦‚å¿µ**: {', '.join(concepts)}")
                        sections.append("")
                    
                    if highlight_analysis.get("themes"):
                        themes = [f"[[{t}]]" for t in highlight_analysis["themes"]]
                        sections.append(f"**ä¸»é¢˜**: {', '.join(themes)}")
                        sections.append("")
                    
                    if highlight_analysis.get("people"):
                        people = [f"[[{p}]]" for p in highlight_analysis["people"]]
                        sections.append(f"**äººç‰©**: {', '.join(people)}")
                        sections.append("")
                    
                    if highlight_analysis.get("tags"):
                        sections.append(f"**æ ‡ç­¾**: {' '.join(highlight_analysis['tags'])}")
                        sections.append("")
                    
                    if highlight_analysis.get("summary"):
                        sections.append(f"**æ‘˜è¦**: {highlight_analysis['summary']}")
                        sections.append("")
                
                sections.append("---")
                sections.append("")
        
        return "\n".join(sections)
    
    def _generate_concept_files(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate concept files"""
        concepts = set()
        
        for result in analysis_result["analysis_results"]:
            concepts.update(result.get("concepts", []))
        
        for concept in concepts:
            self._generate_concept_file(concept, book, analysis_result)
    
    def _generate_concept_file(self, concept: str, book: Book, analysis_result: Dict[str, Any]):
        """Generate a single concept file"""
        filename = self._sanitize_filename(concept) + ".md"
        filepath = self.concepts_dir / filename
        
        content = self._generate_concept_content(concept, book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated concept file: {filepath}")
    
    def _generate_concept_content(self, concept: str, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate content for concept file with enhanced linking"""
        sections = []
        
        sections.append(f"# {concept}")
        sections.append("")
        sections.append(f"**ç±»åž‹**: æ¦‚å¿µ")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        # Add concept tags for Graph View clustering
        concept_type = self._classify_concept_type(concept)
        sections.append(f"**æ¦‚å¿µç±»åž‹**: #{concept_type}")
        sections.append("")
        
        # Find related highlights with enhanced content
        related_highlights = []
        for result in analysis_result["analysis_results"]:
            if concept in result.get("concepts", []):
                related_highlights.append(result)
        
        if related_highlights:
            sections.append("## ðŸ“ ç›¸å…³æ ‡æ³¨")
            sections.append("")
            
            for i, result in enumerate(related_highlights[:3]):  # Show top 3 with more detail
                importance = result.get("importance_score", 0.5)
                sections.append(f"### æ ‡æ³¨ {i+1} (é‡è¦æ€§: {importance:.1f})")
                
                # Add links to other concepts in the same highlight
                other_concepts = [c for c in result.get("concepts", []) if c != concept]
                if other_concepts:
                    concept_links = ", ".join([f"[[{c}]]" for c in other_concepts])
                    sections.append(f"**ç›¸å…³æ¦‚å¿µ**: {concept_links}")
                
                # Add theme links
                themes = result.get("themes", [])
                if themes:
                    theme_links = ", ".join([f"[[{t}]]" for t in themes])
                    sections.append(f"**ç›¸å…³ä¸»é¢˜**: {theme_links}")
                
                # Add people links
                people = result.get("people", [])
                if people:
                    people_links = ", ".join([f"[[{p}]]" for p in people])
                    sections.append(f"**ç›¸å…³äººç‰©**: {people_links}")
                
                sections.append("")
                sections.append(f"> {result.get('summary', 'N/A')}")
                sections.append("")
        
        # Enhanced related concepts with semantic similarity
        related_concepts = self._find_enhanced_related_concepts(concept, analysis_result)
        if related_concepts:
            sections.append("## ðŸ”— ç›¸å…³æ¦‚å¿µ")
            sections.append("")
            for related_concept, strength in related_concepts:
                sections.append(f"- [[{related_concept}]] (å…³è”åº¦: {strength:.2f})")
            sections.append("")
        
        # Add related themes
        related_themes = self._find_related_themes_for_concept(concept, analysis_result)
        if related_themes:
            sections.append("## ðŸŽ­ ç›¸å…³ä¸»é¢˜")
            sections.append("")
            for theme in related_themes:
                sections.append(f"- [[{theme}]]")
            sections.append("")
        
        # Add conceptual network section
        sections.append("## ðŸŒ æ¦‚å¿µç½‘ç»œ")
        sections.append("")
        sections.append(f"æ­¤æ¦‚å¿µåœ¨ [[{book.metadata.title}]] çš„çŸ¥è¯†ç½‘ç»œä¸­èµ·åˆ°é‡è¦ä½œç”¨ã€‚")
        sections.append(f"é€šè¿‡ #æ¦‚å¿µå›¾è°± æ ‡ç­¾å¯åœ¨Graph Viewä¸­æŸ¥çœ‹å®Œæ•´å…³è”ã€‚")
        sections.append("")
        sections.append("### æŽ¢ç´¢å»ºè®®")
        sections.append("- ç‚¹å‡»ç›¸å…³æ¦‚å¿µæ·±å…¥ç†è§£æ¦‚å¿µç¾¤")
        sections.append("- æŸ¥çœ‹ç›¸å…³ä¸»é¢˜äº†è§£æ›´å¹¿æ³›çš„æ€æƒ³èƒŒæ™¯") 
        sections.append("- é€šè¿‡Graph Viewå‘çŽ°æ„æƒ³ä¸åˆ°çš„æ¦‚å¿µè”ç³»")
        sections.append("")
        
        # Add tags for better Graph View organization
        all_tags = ["#æ¦‚å¿µ", f"#{concept_type}", "#æ¦‚å¿µå›¾è°±"]
        sections.append(f"æ ‡ç­¾: {' '.join(all_tags)}")
        sections.append("")
        
        return "\n".join(sections)
    
    def _generate_people_files(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate people files"""
        people = set()
        
        for result in analysis_result["analysis_results"]:
            people.update(result.get("people", []))
        
        for person in people:
            self._generate_person_file(person, book, analysis_result)
    
    def _generate_person_file(self, person: str, book: Book, analysis_result: Dict[str, Any]):
        """Generate a single person file"""
        filename = self._sanitize_filename(person) + ".md"
        filepath = self.people_dir / filename
        
        content = self._generate_person_content(person, book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated person file: {filepath}")
    
    def _generate_person_content(self, person: str, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate content for person file with enhanced linking"""
        sections = []
        
        sections.append(f"# {person}")
        sections.append("")
        sections.append(f"**ç±»åž‹**: äººç‰©")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        # Find related highlights
        related_highlights = []
        for result in analysis_result["analysis_results"]:
            if person in result.get("people", []):
                related_highlights.append(result)
        
        if related_highlights:
            sections.append("## ðŸ“ ç›¸å…³å†…å®¹")
            sections.append("")
            
            for i, result in enumerate(related_highlights[:3]):
                importance = result.get("importance_score", 0.5)
                sections.append(f"### å¼•ç”¨ {i+1} (é‡è¦æ€§: {importance:.1f})")
                
                # Add concept links
                concepts = result.get("concepts", [])
                if concepts:
                    concept_links = ", ".join([f"[[{c}]]" for c in concepts])
                    sections.append(f"**ç›¸å…³æ¦‚å¿µ**: {concept_links}")
                
                # Add theme links  
                themes = result.get("themes", [])
                if themes:
                    theme_links = ", ".join([f"[[{t}]]" for t in themes])
                    sections.append(f"**ç›¸å…³ä¸»é¢˜**: {theme_links}")
                
                sections.append("")
                sections.append(f"> {result.get('summary', 'N/A')}")
                sections.append("")
        
        # Find concepts associated with this person
        related_concepts = self._find_concepts_for_person(person, analysis_result)
        if related_concepts:
            sections.append("## ðŸ§  ç›¸å…³æ¦‚å¿µ")
            sections.append("")
            for concept in related_concepts:
                sections.append(f"- [[{concept}]]")
            sections.append("")
        
        # Find themes associated with this person
        related_themes = self._find_themes_for_person(person, analysis_result)
        if related_themes:
            sections.append("## ðŸŽ­ ç›¸å…³ä¸»é¢˜")
            sections.append("")
            for theme in related_themes:
                sections.append(f"- [[{theme}]]")
            sections.append("")
        
        sections.append("## ðŸŒ äººç‰©ç½‘ç»œ")
        sections.append("")
        sections.append(f"{person} åœ¨ [[{book.metadata.title}]] ä¸­ä¸Žå¤šä¸ªå“²å­¦æ¦‚å¿µç›¸å…³è”ã€‚")
        sections.append("é€šè¿‡ #äººç‰©å›¾è°± æ ‡ç­¾å¯åœ¨Graph Viewä¸­æŸ¥çœ‹äººç‰©å…³ç³»ã€‚")
        sections.append("")
        
        # Add tags
        sections.append("æ ‡ç­¾: #äººç‰© #äººç‰©å›¾è°±")
        sections.append("")
        
        return "\n".join(sections)
    
    def _generate_theme_files(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate theme files"""
        themes = set()
        
        for result in analysis_result["analysis_results"]:
            themes.update(result.get("themes", []))
        
        for theme in themes:
            self._generate_theme_file(theme, book, analysis_result)
    
    def _generate_theme_file(self, theme: str, book: Book, analysis_result: Dict[str, Any]):
        """Generate a single theme file"""
        filename = self._sanitize_filename(theme) + ".md"
        filepath = self.themes_dir / filename
        
        content = self._generate_theme_content(theme, book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated theme file: {filepath}")
    
    def _generate_theme_content(self, theme: str, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate content for theme file with enhanced linking"""
        sections = []
        
        sections.append(f"# {theme}")
        sections.append("")
        sections.append(f"**ç±»åž‹**: ä¸»é¢˜")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        # Find related highlights
        related_highlights = []
        for result in analysis_result["analysis_results"]:
            if theme in result.get("themes", []):
                related_highlights.append(result)
        
        if related_highlights:
            sections.append("## ðŸ“ ç›¸å…³æ ‡æ³¨")
            sections.append("")
            
            for i, result in enumerate(related_highlights[:3]):
                importance = result.get("importance_score", 0.5)
                sections.append(f"### æ ‡æ³¨ {i+1} (é‡è¦æ€§: {importance:.1f})")
                
                # Add concept links
                concepts = result.get("concepts", [])
                if concepts:
                    concept_links = ", ".join([f"[[{c}]]" for c in concepts])
                    sections.append(f"**ç›¸å…³æ¦‚å¿µ**: {concept_links}")
                
                # Add people links
                people = result.get("people", [])
                if people:
                    people_links = ", ".join([f"[[{p}]]" for p in people])
                    sections.append(f"**ç›¸å…³äººç‰©**: {people_links}")
                
                sections.append("")
                sections.append(f"> {result.get('summary', 'N/A')}")
                sections.append("")
        
        # Find related concepts for this theme
        related_concepts = self._find_concepts_for_theme(theme, analysis_result)
        if related_concepts:
            sections.append("## ðŸ§  æ ¸å¿ƒæ¦‚å¿µ")
            sections.append("")
            for concept in related_concepts:
                sections.append(f"- [[{concept}]]")
            sections.append("")
        
        # Find related themes
        related_themes = self._find_related_themes(theme, analysis_result)
        if related_themes:
            sections.append("## ðŸ”— ç›¸å…³ä¸»é¢˜")
            sections.append("")
            for related_theme in related_themes:
                sections.append(f"- [[{related_theme}]]")
            sections.append("")
        
        sections.append("## ðŸŒ ä¸»é¢˜ç½‘ç»œ")
        sections.append("")
        sections.append(f"æ­¤ä¸»é¢˜åœ¨ [[{book.metadata.title}]] ä¸­è´¯ç©¿å¤šä¸ªé‡è¦æ¦‚å¿µã€‚")
        sections.append("é€šè¿‡ #ä¸»é¢˜å›¾è°± æ ‡ç­¾å¯åœ¨Graph Viewä¸­æŸ¥çœ‹ä¸»é¢˜å…³è”ã€‚")
        sections.append("")
        
        # Add tags
        sections.append("æ ‡ç­¾: #ä¸»é¢˜ #ä¸»é¢˜å›¾è°±")
        sections.append("")
        
        return "\n".join(sections)
    
    def _generate_index_file(self):
        """Generate main index file"""
        filepath = self.output_dir / "index.md"
        
        content = self._generate_index_content()
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated index file: {filepath}")
    
    def _generate_concepts_overview_file(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate aggregated concepts overview file"""
        filename = f"{self._sanitize_filename(book.metadata.title)}_æ¦‚å¿µæ€»è§ˆ.md"
        filepath = self.concepts_dir / filename
        
        content = self._generate_concepts_overview_content(book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated concepts overview file: {filepath}")
    
    def _generate_concepts_overview_content(self, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate concepts overview content"""
        sections = []
        
        sections.append(f"# {book.metadata.title} - æ¦‚å¿µæ€»è§ˆ")
        sections.append("")
        sections.append(f"**ä½œè€…**: {book.metadata.author}")
        sections.append(f"**ç±»åž‹**: æ¦‚å¿µæ€»è§ˆ")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        # Collect and organize concepts
        concept_highlights = {}
        for i, result in enumerate(analysis_result["analysis_results"]):
            highlight = book.highlights[i]
            for concept in result.get("concepts", []):
                if concept not in concept_highlights:
                    concept_highlights[concept] = []
                concept_highlights[concept].append({
                    'content': highlight.content,
                    'importance': result.get('importance_score', 0.5),
                    'summary': result.get('summary', '')
                })
        
        # Sort concepts by importance and frequency
        sorted_concepts = sorted(concept_highlights.items(), 
                               key=lambda x: (len(x[1]), max(h['importance'] for h in x[1])), 
                               reverse=True)
        
        sections.append("## ðŸ“Š æ¦‚å¿µç»Ÿè®¡")
        sections.append("")
        sections.append(f"- æ€»æ¦‚å¿µæ•°: {len(sorted_concepts)}")
        sections.append(f"- ä¸»è¦æ¦‚å¿µ: {', '.join([c[0] for c in sorted_concepts[:5]])}")
        sections.append("")
        
        sections.append("## ðŸ’¡ æ ¸å¿ƒæ¦‚å¿µè¯¦è§£")
        sections.append("")
        
        for concept, highlights in sorted_concepts:
            sections.append(f"### {concept}")
            sections.append("")
            sections.append(f"**å‡ºçŽ°æ¬¡æ•°**: {len(highlights)}")
            
            # Show most important highlight for this concept
            best_highlight = max(highlights, key=lambda x: x['importance'])
            sections.append(f"**æœ€é‡è¦æ ‡æ³¨** (é‡è¦æ€§: {best_highlight['importance']:.1f}):")
            sections.append(f"> {best_highlight['content']}")
            sections.append("")
            
            if best_highlight['summary']:
                sections.append(f"**åˆ†æž**: {best_highlight['summary']}")
                sections.append("")
            
            # Show other related highlights (up to 2 more)
            other_highlights = [h for h in highlights if h != best_highlight][:2]
            if other_highlights:
                sections.append("å…¶ä»–ç›¸å…³æ ‡æ³¨:")
                for h in other_highlights:
                    sections.append(f"- {h['content'][:80]}...")
                sections.append("")
        
        return "\n".join(sections)
    
    def _generate_themes_overview_file(self, book: Book, analysis_result: Dict[str, Any]):
        """Generate aggregated themes overview file"""
        filename = f"{self._sanitize_filename(book.metadata.title)}_ä¸»é¢˜æ€»è§ˆ.md"
        filepath = self.themes_dir / filename
        
        content = self._generate_themes_overview_content(book, analysis_result)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated themes overview file: {filepath}")
    
    def _generate_themes_overview_content(self, book: Book, analysis_result: Dict[str, Any]) -> str:
        """Generate themes overview content"""
        sections = []
        
        sections.append(f"# {book.metadata.title} - ä¸»é¢˜æ€»è§ˆ")
        sections.append("")
        sections.append(f"**ä½œè€…**: {book.metadata.author}")
        sections.append(f"**ç±»åž‹**: ä¸»é¢˜æ€»è§ˆ")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        # Collect and organize themes
        theme_highlights = {}
        for i, result in enumerate(analysis_result["analysis_results"]):
            highlight = book.highlights[i]
            for theme in result.get("themes", []):
                if theme not in theme_highlights:
                    theme_highlights[theme] = []
                theme_highlights[theme].append({
                    'content': highlight.content,
                    'importance': result.get('importance_score', 0.5),
                    'summary': result.get('summary', '')
                })
        
        # Sort themes by importance and frequency
        sorted_themes = sorted(theme_highlights.items(), 
                              key=lambda x: (len(x[1]), max(h['importance'] for h in x[1])), 
                              reverse=True)
        
        sections.append("## ðŸ“Š ä¸»é¢˜ç»Ÿè®¡")
        sections.append("")
        sections.append(f"- æ€»ä¸»é¢˜æ•°: {len(sorted_themes)}")
        sections.append(f"- ä¸»è¦ä¸»é¢˜: {', '.join([t[0] for t in sorted_themes[:3]])}")
        sections.append("")
        
        sections.append("## ðŸŽ­ ä¸»é¢˜è¯¦è§£")
        sections.append("")
        
        for theme, highlights in sorted_themes:
            sections.append(f"### {theme}")
            sections.append("")
            sections.append(f"**æ¶µç›–æ ‡æ³¨**: {len(highlights)} ä¸ª")
            
            # Show most important highlights for this theme
            top_highlights = sorted(highlights, key=lambda x: x['importance'], reverse=True)[:3]
            sections.append("ä»£è¡¨æ€§æ ‡æ³¨:")
            for i, h in enumerate(top_highlights, 1):
                sections.append(f"{i}. {h['content'][:120]}... (é‡è¦æ€§: {h['importance']:.1f})")
            sections.append("")
        
        return "\n".join(sections)
    
    def _generate_people_overview_file(self, book: Book, analysis_result: Dict[str, Any], all_people: List[str]):
        """Generate aggregated people overview file"""
        filename = f"{self._sanitize_filename(book.metadata.title)}_äººç‰©æ€»è§ˆ.md"
        filepath = self.people_dir / filename
        
        content = self._generate_people_overview_content(book, analysis_result, all_people)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"Generated people overview file: {filepath}")
    
    def _generate_people_overview_content(self, book: Book, analysis_result: Dict[str, Any], all_people: List[str]) -> str:
        """Generate people overview content"""
        sections = []
        
        sections.append(f"# {book.metadata.title} - äººç‰©æ€»è§ˆ")
        sections.append("")
        sections.append(f"**ä½œè€…**: {book.metadata.author}")
        sections.append(f"**ç±»åž‹**: äººç‰©æ€»è§ˆ")
        sections.append(f"**æ¥æºä¹¦ç±**: [[{book.metadata.title}]]")
        sections.append("")
        
        sections.append("## ðŸ‘¥ æ¶‰åŠäººç‰©")
        sections.append("")
        
        # Collect mentions for each person
        person_mentions = {}
        for i, result in enumerate(analysis_result["analysis_results"]):
            highlight = book.highlights[i]
            for person in result.get("people", []):
                if person not in person_mentions:
                    person_mentions[person] = []
                person_mentions[person].append(highlight.content)
        
        for person in all_people:
            sections.append(f"### {person}")
            sections.append("")
            if person in person_mentions:
                sections.append(f"**æåŠæ¬¡æ•°**: {len(person_mentions[person])}")
                sections.append("ç›¸å…³æ ‡æ³¨:")
                for mention in person_mentions[person][:3]:  # Show top 3 mentions
                    sections.append(f"- {mention[:100]}...")
            sections.append("")
        
        return "\n".join(sections)
    
    def _generate_index_content(self) -> str:
        """Generate enhanced content for index file with graph navigation"""
        sections = []
        
        sections.append("# ðŸ“š æ™ºèƒ½çŸ¥è¯†å›¾è°± - ObsidianåŒå‘é“¾æŽ¥ç½‘ç»œ")
        sections.append("")
        sections.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        sections.append("")
        
        sections.append("## ðŸŒ å›¾è°±å¯¼èˆª")
        sections.append("")
        sections.append("### ðŸ“ˆ Graph View ä½¿ç”¨æŒ‡å—")
        sections.append("1. æ‰“å¼€ **Graph View** (Ctrl/Cmd + G) æŸ¥çœ‹å®Œæ•´çŸ¥è¯†ç½‘ç»œ")
        sections.append("2. ä½¿ç”¨ä»¥ä¸‹æ ‡ç­¾è¿‡æ»¤ä¸åŒç±»åž‹çš„èŠ‚ç‚¹:")
        sections.append("   - `#æ¦‚å¿µ` - æŸ¥çœ‹æ‰€æœ‰æ¦‚å¿µåŠå…¶å…³è”")
        sections.append("   - `#ä¸»é¢˜` - æŸ¥çœ‹ä¸»é¢˜ç½‘ç»œ")
        sections.append("   - `#äººç‰©` - æŸ¥çœ‹äººç‰©å…³ç³»")
        sections.append("   - `#æ¦‚å¿µå›¾è°±` - ä¸“æ³¨äºŽæ¦‚å¿µå…³ç³»ç½‘ç»œ")
        sections.append("3. ç‚¹å‡»ä»»æ„èŠ‚ç‚¹æ·±å…¥æŽ¢ç´¢ç›¸å…³å†…å®¹")
        sections.append("4. è°ƒæ•´ **Link Distance** å’Œ **Repel Force** ä¼˜åŒ–å›¾è°±å¸ƒå±€")
        sections.append("")
        
        sections.append("### ðŸŽ¯ æ™ºèƒ½æŽ¢ç´¢å…¥å£")
        sections.append("")
        
        # Books with enhanced linking
        if self.books_dir.exists():
            books = list(self.books_dir.glob("*.md"))
            if books:
                sections.append("## ðŸ“– ä¹¦ç±åˆ†æž")
                sections.append("")
                for book_file in sorted(books):
                    book_name = book_file.stem
                    sections.append(f"- [[{book_name}]] - å®Œæ•´çš„æ¦‚å¿µä¸Žä¸»é¢˜ç½‘ç»œ")
                sections.append("")
        
        # Concepts with categorization
        if self.concepts_dir.exists():
            concepts = list(self.concepts_dir.glob("*.md"))
            if concepts:
                sections.append(f"## ðŸ’¡ æ ¸å¿ƒæ¦‚å¿µ ({len(concepts)} ä¸ª)")
                sections.append("")
                sections.append("### ðŸ”¥ çƒ­é—¨æ¦‚å¿µ (ç‚¹å‡»æŽ¢ç´¢å…³è”ç½‘ç»œ)")
                # Show first 10 as hot concepts
                for concept_file in sorted(concepts)[:10]:
                    concept_name = concept_file.stem
                    sections.append(f"- [[{concept_name}]] #çƒ­é—¨æ¦‚å¿µ")
                
                if len(concepts) > 10:
                    sections.append("")
                    sections.append("### ðŸ“‹ å®Œæ•´æ¦‚å¿µåˆ—è¡¨")
                    sections.append("")
                    for concept_file in sorted(concepts)[10:]:
                        concept_name = concept_file.stem
                        sections.append(f"- [[{concept_name}]]")
                sections.append("")
        
        # Themes
        if self.themes_dir.exists():
            themes = list(self.themes_dir.glob("*.md"))
            if themes:
                sections.append(f"## ðŸŽ­ æ ¸å¿ƒä¸»é¢˜ ({len(themes)} ä¸ª)")
                sections.append("")
                for theme_file in sorted(themes):
                    theme_name = theme_file.stem
                    sections.append(f"- [[{theme_name}]]")
                sections.append("")
        
        # People
        if self.people_dir.exists():
            people = list(self.people_dir.glob("*.md"))
            if people:
                sections.append(f"## ðŸ‘¥ é‡è¦äººç‰© ({len(people)} ä¸ª)")
                sections.append("")
                for person_file in sorted(people):
                    person_name = person_file.stem
                    sections.append(f"- [[{person_name}]]")
                sections.append("")
        
        # Navigation tips
        sections.append("## ðŸ§­ çŸ¥è¯†æŽ¢ç´¢å»ºè®®")
        sections.append("")
        sections.append("### ðŸ” å‘çŽ°æ–°è”ç³»")
        sections.append("- **ä»Žæ¦‚å¿µå¼€å§‹**: é€‰æ‹©æ„Ÿå…´è¶£çš„æ¦‚å¿µï¼ŒæŸ¥çœ‹å…¶ç›¸å…³æ¦‚å¿µç½‘ç»œ")
        sections.append("- **ä¸»é¢˜å¯¼èˆª**: é€šè¿‡ä¸»é¢˜é¡µé¢äº†è§£æŸä¸ªæ€æƒ³é¢†åŸŸçš„å®Œæ•´æ¦‚å¿µç¾¤")
        sections.append("- **äººç‰©è§†è§’**: ä»Žé‡è¦äººç‰©å‡ºå‘ï¼Œäº†è§£å…¶ç›¸å…³çš„å“²å­¦æ€æƒ³")
        sections.append("- **Graph Viewæ¼«æ¸¸**: åœ¨å›¾è°±ä¸­è‡ªç”±æŽ¢ç´¢ï¼Œå‘çŽ°æ„æƒ³ä¸åˆ°çš„æ¦‚å¿µè”ç³»")
        sections.append("")
        
        sections.append("### ðŸŽ¨ ä¸ªæ€§åŒ–æŽ¢ç´¢")
        sections.append("- ä½¿ç”¨ **Local Graph** æŸ¥çœ‹å½“å‰é¡µé¢çš„å±€éƒ¨å…³ç³»")
        sections.append("- é€šè¿‡ **Filter** é¢æ¿è‡ªå®šä¹‰æ˜¾ç¤ºå†…å®¹")  
        sections.append("- ä¿å­˜æœ‰è¶£çš„å›¾è°±è§†å›¾æˆªå›¾ä½œä¸ºæ€ç»´å¯¼å›¾")
        sections.append("")
        
        sections.append("---")
        sections.append("")
        sections.append("**ðŸš€ å¼€å§‹æŽ¢ç´¢**: ç‚¹å‡»ä¸Šæ–¹ä»»æ„é“¾æŽ¥ï¼Œå¼€å§‹ä½ çš„çŸ¥è¯†å‘çŽ°ä¹‹æ—…ï¼")
        sections.append("")
        
        # Meta tags for graph organization
        sections.append("æ ‡ç­¾: #ç´¢å¼• #å¯¼èˆª #çŸ¥è¯†å›¾è°±")
        sections.append("")
        
        return "\n".join(sections)
    
    def _find_highlight_analysis(self, highlight, analysis_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Find analysis result for a specific highlight"""
        highlight_id = f"{highlight.location.page}_{highlight.location.position}"
        
        for result in analysis_results:
            if result.get("highlight_id") == highlight_id:
                return result
        
        return {}
    
    def _find_related_concepts(self, concept: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find concepts that often appear together"""
        concept_cooccurrence = {}
        
        for result in analysis_result["analysis_results"]:
            concepts = result.get("concepts", [])
            if concept in concepts:
                for other_concept in concepts:
                    if other_concept != concept:
                        concept_cooccurrence[other_concept] = concept_cooccurrence.get(other_concept, 0) + 1
        
        # Sort by frequency and return top 5
        sorted_concepts = sorted(concept_cooccurrence.items(), key=lambda x: x[1], reverse=True)
        return [concept for concept, count in sorted_concepts[:5]]
    
    def _find_enhanced_related_concepts(self, concept: str, analysis_result: Dict[str, Any]) -> List[Tuple[str, float]]:
        """Find related concepts with semantic similarity scoring"""
        concept_scores = {}
        concept_total_importance = {}
        
        for result in analysis_result["analysis_results"]:
            concepts = result.get("concepts", [])
            importance = result.get("importance_score", 0.5)
            
            if concept in concepts:
                for other_concept in concepts:
                    if other_concept != concept:
                        # Weight by importance and co-occurrence
                        concept_scores[other_concept] = concept_scores.get(other_concept, 0) + importance
                        concept_total_importance[other_concept] = concept_total_importance.get(other_concept, 0) + 1
        
        # Calculate relationship strength (average importance * frequency factor)
        related_concepts = []
        for other_concept, total_importance in concept_scores.items():
            frequency = concept_total_importance[other_concept]
            # Relationship strength = average importance * log(frequency + 1)
            import math
            strength = (total_importance / frequency) * math.log(frequency + 1)
            related_concepts.append((other_concept, strength))
        
        # Sort by strength and return top 5
        related_concepts.sort(key=lambda x: x[1], reverse=True)
        return related_concepts[:5]
    
    def _find_related_themes_for_concept(self, concept: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find themes that are associated with this concept"""
        theme_counts = {}
        
        for result in analysis_result["analysis_results"]:
            concepts = result.get("concepts", [])
            themes = result.get("themes", [])
            
            if concept in concepts:
                for theme in themes:
                    theme_counts[theme] = theme_counts.get(theme, 0) + 1
        
        # Sort by frequency and return top 3
        sorted_themes = sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)
        return [theme for theme, count in sorted_themes[:3]]
    
    def _classify_concept_type(self, concept: str) -> str:
        """Classify concept type for better organization"""
        concept_lower = concept.lower()
        
        # å“²å­¦æ¦‚å¿µ
        if any(word in concept_lower for word in ['å­˜åœ¨', 'è‡ªç”±', 'æ„å¿—', 'çœŸç†', 'æœ¬è´¨', 'è¶…è¶Š', 'æ°¸æ’', 'è™šæ— ']):
            return "å“²å­¦æ¦‚å¿µ"
        
        # å¿ƒç†å­¦æ¦‚å¿µ  
        if any(word in concept_lower for word in ['ç„¦è™‘', 'ææƒ§', 'æ¬²æœ›', 'æƒ…æ„Ÿ', 'å¿ƒç†', 'æ„è¯†', 'æ½œæ„è¯†']):
            return "å¿ƒç†æ¦‚å¿µ"
        
        # äººé™…å…³ç³»
        if any(word in concept_lower for word in ['å…³ç³»', 'å©šå§»', 'çˆ±æƒ…', 'å‹è°Š', 'äº²è¿‘', 'å­¤ç‹¬', 'è¿žæŽ¥']):
            return "å…³ç³»æ¦‚å¿µ"
        
        # ä»·å€¼è§‚å¿µ
        if any(word in concept_lower for word in ['é“å¾·', 'è´£ä»»', 'é€‰æ‹©', 'ä»·å€¼', 'æ„ä¹‰', 'ç›®æ ‡']):
            return "ä»·å€¼æ¦‚å¿µ"
        
        # ç”Ÿå‘½å“²å­¦
        if any(word in concept_lower for word in ['ç”Ÿå‘½', 'æ­»äº¡', 'ç”Ÿæ´»', 'äººç”Ÿ', 'å‘½è¿', 'æ—¶é—´']):
            return "ç”Ÿå‘½æ¦‚å¿µ"
        
        # é»˜è®¤
        return "æ ¸å¿ƒæ¦‚å¿µ"
    
    def _find_concepts_for_theme(self, theme: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find concepts that belong to this theme"""
        concept_counts = {}
        
        for result in analysis_result["analysis_results"]:
            themes = result.get("themes", [])
            concepts = result.get("concepts", [])
            
            if theme in themes:
                for concept in concepts:
                    concept_counts[concept] = concept_counts.get(concept, 0) + 1
        
        # Sort by frequency and return top 5
        sorted_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)
        return [concept for concept, count in sorted_concepts[:5]]
    
    def _find_related_themes(self, theme: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find themes that often appear together with this theme"""
        theme_cooccurrence = {}
        
        for result in analysis_result["analysis_results"]:
            themes = result.get("themes", [])
            if theme in themes:
                for other_theme in themes:
                    if other_theme != theme:
                        theme_cooccurrence[other_theme] = theme_cooccurrence.get(other_theme, 0) + 1
        
        # Sort by frequency and return top 3
        sorted_themes = sorted(theme_cooccurrence.items(), key=lambda x: x[1], reverse=True)
        return [theme for theme, count in sorted_themes[:3]]
    
    def _find_concepts_for_person(self, person: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find concepts associated with this person"""
        concept_counts = {}
        
        for result in analysis_result["analysis_results"]:
            people = result.get("people", [])
            concepts = result.get("concepts", [])
            
            if person in people:
                for concept in concepts:
                    concept_counts[concept] = concept_counts.get(concept, 0) + 1
        
        # Sort by frequency and return top 5
        sorted_concepts = sorted(concept_counts.items(), key=lambda x: x[1], reverse=True)
        return [concept for concept, count in sorted_concepts[:5]]
    
    def _find_themes_for_person(self, person: str, analysis_result: Dict[str, Any]) -> List[str]:
        """Find themes associated with this person"""
        theme_counts = {}
        
        for result in analysis_result["analysis_results"]:
            people = result.get("people", [])
            themes = result.get("themes", [])
            
            if person in people:
                for theme in themes:
                    theme_counts[theme] = theme_counts.get(theme, 0) + 1
        
        # Sort by frequency and return top 3
        sorted_themes = sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)
        return [theme for theme, count in sorted_themes[:3]]
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for file system"""
        # Remove or replace invalid characters
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        # Remove excessive whitespace
        filename = ' '.join(filename.split())
        
        # Limit length
        if len(filename) > 100:
            filename = filename[:100]
        
        return filename