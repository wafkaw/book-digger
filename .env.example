# Kindle Reading Assistant Environment Configuration
# Copy this file to .env and fill in your actual values

# OpenAI-Compatible API Configuration
OPENAI_API_KEY=your_api_key_here
OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4/  # 智谱AI API地址，也可以是其他OpenAI兼容API
OPENAI_MODEL=glm-4-flash  # 智谱AI模型，也可以用gpt-4o-mini等
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.1
OPENAI_TIMEOUT=600  # 10分钟超时，防止长时间等待
OPENAI_MAX_RETRIES=3  # 失败时最多重试3次

# API Cost Control
MAX_DAILY_API_COST=10.0
BATCH_PROCESSING_SIZE=5
ENABLE_CACHING=true
CACHE_TTL_HOURS=24

# Local Model Configuration (Ollama)
OLLAMA_ENABLED=false
OLLAMA_MODEL=qwen2.5:32b
OLLAMA_BASE_URL=http://localhost:11434

# Redis Cache Configuration (Optional)
REDIS_URL=redis://localhost:6379/0

# Application Settings
AI_MOCK_MODE=false
AI_MAX_CONCEPTS=5
AI_MAX_THEMES=3
AI_MAX_EMOTIONS=3
AI_BATCH_SIZE=5  # AI分析批量处理大小，每次处理的标注数量

# Analysis Quality Settings (性能优化相关)
AI_QUALITY_MODE=balanced  # strict=严格模式, balanced=平衡模式, permissive=宽松模式
AI_MIN_CONCEPT_LENGTH=3  # 概念最小长度，过短的概念会被过滤
AI_MIN_IMPORTANCE_THRESHOLD=0.3  # 最低重要性阈值，低于此值的标注会被过滤

# Output Settings (输出优化相关)
OUTPUT_AGGREGATED_MODE=true  # true=聚合模式(生成少量丰富文件), false=分散模式(每概念一文件)
OUTPUT_MAX_HIGHLIGHTS_PER_CONCEPT=3  # 每个概念显示的最大标注数量

LOG_LEVEL=INFO
MIN_HIGHLIGHT_LENGTH=10
MAX_HIGHLIGHT_LENGTH=2000
BATCH_SIZE=10

# Knowledge Graph Settings
MIN_RELATIONSHIP_WEIGHT=0.1
MAX_NODES_PER_TYPE=100

# Obsidian Settings
OBSIDIAN_BOOKS_DIR=books
OBSIDIAN_CONCEPTS_DIR=concepts
OBSIDIAN_PEOPLE_DIR=people
OBSIDIAN_THEMES_DIR=themes